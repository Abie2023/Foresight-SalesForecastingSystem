version: '3.8'

services:

    # dev workspace
    jupyter:
        # platform: linux/x86_64 # for others (mostly) or can just remove this line
        platform: linux/arm64 # for Mac M1
        container_name: jupyter_dev_repo
        shm_size: '2gb'
        build:
            context: ./services/jupyter
            dockerfile: Dockerfile
            args:
                NB_USER: ${JUPYTER_USER}
                NB_PWD: 123456789
                NB_UID: 1412
                CONDA_DIR: /opt/anaconda3
                ARCH: aarch64 # aarch64 for Mac M1 | x86_64 for others (mostly)
                JUPYTER_PORT: ${JUPYTER_PORT}
                MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}
                CENTRAL_STORAGE_PATH: /home/${JUPYTER_USER}/central_storage
                MAIN_CONDA_ENV_NAME: computer-viz-dl
        env_file:
            - .env
        environment:
            - MLFLOW_TRACKING_URI=http://mlflow:${MLFLOW_PORT}
        networks:
            - forecast_network
        ports: 
            - "${JUPYTER_PORT}:${JUPYTER_PORT}"
        volumes:
            - ./:/home/${JUPYTER_USER}/workspace/
            - mlflow_data:${MLFLOW_ARTIFACT_ROOT}
            - conda_data:/opt/anaconda3

    kafka:
        platform: linux/arm64
        container_name: kafka
        image: bitnami/kafka:latest
        ports:
            - 9094:9094
        networks:
            - forecast_network
        environment:
            - KAFKA_CFG_NODE_ID=0
            - KAFKA_CFG_PROCESS_ROLES=controller,broker
            - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
            - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
            - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
            - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
            - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
        volumes:
            - kafka_data:/bitnami/kafka

    # sales forecasst service
    forecast_service:
        platform: linux/arm64
        image: ariya23156/sale-forecast-service:latest
        container_name: forecast_service
        build:
            context: ./services/forecast_service
            dockerfile: Dockerfile
            args:
                FORECAST_SERVICE_PORT: ${FORECAST_SERVICE_PORT}
        env_file:
            - .env
        environment:
            - MLFLOW_TRACKING_URI=http://mlflow:${MLFLOW_PORT}
        networks:
            - forecast_network
        # ports:
        #     - ${FORECAST_SERVICE_PORT}:${FORECAST_SERVICE_PORT}
        volumes:
            - mlflow_data:${MLFLOW_ARTIFACT_ROOT}:ro

    # Web UI interface
    web_ui:
        platform: linux/arm64
        container_name: web_ui
        build:
            context: ./services/web_ui
            dockerfile: Dockerfile
            args:
                WEB_UI_PORT: ${WEB_UI_PORT}
        env_file:
            - .env
        environment:
            - FORECAST_ENDPOINT_URI=http://nginx/api/forecasters/forecast
        networks:
            - forecast_network
        # ports:
        #     - ${WEB_UI_PORT}:${WEB_UI_PORT}
        volumes:
            - /Users/ariyasontrapornpol/Desktop/personal_projects/dev_workspace/dev_repos/sales-forecast-mlops-at-scale/services/web_ui/app/main.py:/service/app/main.py

    # service for triggering training/retraining
    training_service:
        platform: linux/arm64
        container_name: training_service
        build:
            context: ./services/training_service
            dockerfile: Dockerfile
            args:
                FORECAST_SERVICE_PORT: ${TRAINING_SERVICE_PORT}
                MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}
        env_file:
            - .env
        environment:
            # - RAY_ADDRESS=ray://ray:${RAY_HEAD_PORT}
            - MLFLOW_TRACKING_URI=http://mlflow:${MLFLOW_PORT}
            - DB_CONNECTION_URL=postgresql://spark_user:SuperSecurePwdHere@postgres:${POSTGRES_PORT}/spark_pg_db
        networks:
            - forecast_network
        depends_on:
            - ray
        # ports:
        #     - ${TRAINING_SERVICE_PORT}:${TRAINING_SERVICE_PORT}
        volumes:
            - ./services/training_service/app/:/service/app/
            - mlflow_data:${MLFLOW_ARTIFACT_ROOT}

    ray:
        platform: linux/arm64
        image: rayproject/ray:2.9.3-py39-cpu-aarch64
        build:
            context: ./services/ray
            dockerfile: Dockerfile
            args:
                MLFLOW_ARTIFACT_ROOT: ${MLFLOW_ARTIFACT_ROOT}
        shm_size: '2gb'
        env_file:
            - .env
        environment:
            - RAY_REDIS_ADDRESS=redis:${REDIS_PORT}
        networks:
            - forecast_network
        ports:
            - ${RAY_DASHBOARD_PORT}:${RAY_DASHBOARD_PORT} # port for ray dashboard
        # command: sleep infinity
        # command: ray start --head --port=${RAY_HEAD_PORT} --dashboard-host=0.0.0.0 --dashboard-port=${RAY_DASHBOARD_PORT} --ray-client-server-port=${RAY_CLIENT_SERVER_PORT} --block

    nginx:
        platform: linux/arm64
        container_name: nginx
        # restart: always
        build:
            context: ./services/nginx
            dockerfile: Dockerfile
        env_file:
            - .env
        networks:
            - forecast_network
        ports:
            - ${NGINX_PORT}:${NGINX_PORT}
        depends_on:
            - forecast_service
            - web_ui
            - training_service

    # ML platform / experiment tracking
    mlflow:
        platform: linux/arm64
        container_name: mlflow_server
        # restart: always
        build:
            context: ./services/mlflow
            dockerfile: Dockerfile
            args:
                MLFLOW_PORT: ${MLFLOW_PORT}
        env_file:
            - .env
        environment:
            - BACKEND_STORE_URI=postgresql://mlflow_user:SuperSecurePwdHere@postgres:${POSTGRES_PORT}/mlflow_pg_db
        networks:
            - forecast_network
        ports:
            - "${MLFLOW_PORT}:${MLFLOW_PORT}"
        volumes:
            - mlflow_data:${MLFLOW_ARTIFACT_ROOT}
        depends_on:
            postgres:
                condition: service_healthy

    # sql database
    postgres:
        platform: linux/arm64
        container_name: postgres_server
        image: postgres:15.3
        # restart: always
        environment:
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres
            - POSTGRES_DB=postgres
        networks:
            - forecast_network
        volumes:
            - ./services/postgres/docker_postgres_init.sql:/docker-entrypoint-initdb.d/docker_postgres_init.sql
            - pgdata:/var/lib/postgresql/data
        healthcheck:
            test: ["CMD-SHELL", "pg_isready -U postgres"]
            interval: 5s
            timeout: 5s
            retries: 5
    
    # ui for database
    pgadmin:
        platform: linux/arm64
        image: dpage/pgadmin4
        # restart: always
        environment:
            - PGADMIN_DEFAULT_EMAIL=pgadmin@gmail.com
            - PGADMIN_DEFAULT_PASSWORD=SuperSecurePwdHere
        networks:
            - forecast_network
        ports:
            - "16543:80"
        volumes:
            - pgadmin_data:/var/lib/pgadmin
        depends_on:
            postgres:
                condition: service_healthy

    # bring out from airflow compose
    redis:
        image: redis:latest
        expose:
            - 6379
        healthcheck:
            test: ["CMD", "redis-cli", "ping"]
            interval: 10s
            timeout: 30s
            retries: 50
            start_period: 30s
        restart: always
        networks:
            - forecast_network

networks:
    forecast_network:
        driver: "bridge"

volumes:
    mlflow_data:
    pgdata:
    pgadmin_data:
    kafka_data:
    # for dev
    conda_data:
    